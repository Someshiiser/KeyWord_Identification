{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f3353b",
   "metadata": {},
   "source": [
    "Key Word Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "397f0d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ad492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str):\n",
    "    # Convert text to lowercase for uniformity\n",
    "    text = text.lower()\n",
    "    # Remove all non-alphabetic characters (retain spaces)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    # Remove single-letter words except 'a' and 'i'\n",
    "    text = re.sub(r'\\b(?![ai]\\b)[a-z]\\b', ' ', text)\n",
    "    # Replace multiple spaces with a single space and strip leading/trailing spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Somesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_text_from_url(url: str) -> str:\n",
    "    # Automatically fetch the HTML Content of the webpage.\n",
    "    response = requests.get(url)\n",
    "    # Response code 200 means it was successful.\n",
    "    # Other response codes mean there was an error,\n",
    "    # You can check the list of response codes.\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # We are assuming that all text content is within these tags.\n",
    "        # This is a very basic assumption and may not work for all websites.\n",
    "        # Best way to check is to inspect the website and see where the text lies.\n",
    "        # You can watch a basic video on how html works.\n",
    "        valid_tags = ['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'li']\n",
    "        #connect all the text in the valid tags\n",
    "        text = \" \".join(element.get_text() for element in soup.find_all(valid_tags))\n",
    "        text = clean_text(text)\n",
    "        \n",
    "        return text\n",
    "    else:\n",
    "        # Sometimes while fetching the URL,\n",
    "        # there might be some unrecoverable error\n",
    "        raise Exception(f\"Failed to fetch the URL: {url}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dsenv)",
   "language": "python",
   "name": "dsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
