{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a1a7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the webpage!\n"
     ]
    }
   ],
   "source": [
    "import requests  # Python library to send HTTP requests.\n",
    "\n",
    "url = \"https://www.iisermohali.ac.in/\"\n",
    "#url= \"https://timesofindia.indiatimes.com/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if request succeeded\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text  # This is the raw HTML\n",
    "    print(\"Successfully fetched the webpage!\")\n",
    "else:\n",
    "    print(\"Failed to fetch the webpage. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8dbc4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " IISER MOHALI Institute Academics Research People Outreach 79th Independence Day Celebration at IISER Mohali International Yoga Day Celebration at IISER Mohali IISER Mohali awarded degrees to 316 Graduating Students IISER Mohali Science Festival - Inaugurated by Hon'ble Education Minister of Punjab Science demonstrations & competitions The Hon'ble Vice-President of India interacts with IISER Mohali Faculty, Students & Staff Visit of Hon'ble Vice-President of India to IISER Mohali Tattva 2025 Science Fest - Celebrating the essence of Scientific Curiosity  76th Republic Day Celebration at IISER Mohali 500+ School students at IISER Mohali for National Space Day Annual Science Festival Lectures by Dr. Anjan Ray & Dr. Srivari Chandrashekhar Students awarded for outstanding performance in Academics & Sports FACULTY ACHIEVEMENTS PROFESSOR ANIL KUMAR TRIPATHI Director, IISER Mohali Elected as Vice President (Science Promotion) of INSA  1800 school students across tricity visited IISER Mohali  SPOTLIGHTS  DEPARTMENTS  ACADEMIC PROGRAMMES  EVENTS UPCOMING GALLERY\n",
      "\n",
      " website policy  Copyright Policy  Privacy Policy  Terms of use  Website Feedback Connect with us IISER Mohali, Knowledge city, Sector 81, SAS Nagar, Manauli PO 140306Telefax : 2240266, 2240124 \n",
      "+91 - 172 - 2240266\n",
      " +91 - 172 - 2240266 +91 - 172 - 2240266    Administrative Sections  Directorate  Registrar Office  General Administration  Recruitment  Establishment  Purchase & Stores Campus Facilities   Library   Computer Center  Visitors Hostel  Institute Dispensary  Sports Facilities  Counselling Service  Transport  Day Care Departments   Biological Sciences   Physical Sciences   Chemical Sciences   Mathematical Sciences   Humanities & Social Sciences   Earth & Environmental Sciences committees  Central Research Facility Committees  NIRF   ICC - Internal Complaints Committee  Grievance Committee  SC/ST/OBC Committee  Safety & Ethics Committees  Research Advisory Committee  Others Archive  Public Lectures   Conferences  News Archives  In the Media  Press Release  Institute Events  Events Calendar  Faculty Achievements  Alumni News Links  Academies of Science   CCS Conduct Rules  Funding Agencies  MHRD Funded Institutes  CRIKC Institutes   MoE   IISER System Quick Find  Admission News  Anti-ragging committee  Campus Facilities  Convocation  Careers  Download Forms   ERP  eSanad   Holiday Calendar-2025   Holiday Calendar-2026  Home   Hostel Rules & Guidelines  ICC - Internal Complaints Committee   MOODLE  News & Announcements  NIRF   Opportunity Cell  Reach Us  RTI   SRC - Student Representative Council   Ticketing System Advertisements   Tenders / EOI CAREERS  Faculty Recruitments  Research Positions  Non-Teaching Positions © Copyright IISER Mohali  2025.     |     Hosting & Maintenance by IISER Mohali Computer Center     |     Image Credits - IISERM Lumiere Club & Community Members  Institute  Academics  Research  People  Outreach Search\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "# html\n",
    "# ├── head\n",
    "# │   └── title → 'IISER Mohali'\n",
    "# └── body\n",
    "#     ├── h1 → 'Welcome to IISER Mohali'\n",
    "#     ├── p  → 'Indian Institute...'\n",
    "#     └── p  → 'Established by...'\n",
    "# We are assuming that all text content is within these tags.\n",
    "# This is a very basic assumption and may not work for all websites.\n",
    "# Best way to check is to inspect the website and see where the text lies.\n",
    "# Extract text from common tags\n",
    "valid_tags = ['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'li'] # valid tags only from the html file, h->heading, p->paragraph, li->list\n",
    "text = \" \".join([element.get_text() for element in soup.find_all(valid_tags)]) # join the entire string into one.\n",
    "\n",
    "print(text[:])  # print characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344cf0f7",
   "metadata": {},
   "source": [
    "Now after getting the 'text' part , our next step is to clean the text we get after parsing.\n",
    "This includes getting rid of symbols , punctuations and numbers and converting all the text to lower case, so that we can standardize the text for word frequency analysis . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean(text:str) -> str:\n",
    "\n",
    "   text = text.lower() #convert text to lower case\n",
    "\n",
    "   text =re.sub(r'[^a-z\\s]', ' ',text)\n",
    "\n",
    "   text = re.sub(r'\\b(?![ai]\\b)[a-z]\\b',' ',text)\n",
    "\n",
    "   text = re.sub(r'\\s+',' ',text).strip()\n",
    "\n",
    "   return text\n",
    "\n",
    "clean(text)\n",
    "\n",
    "cleaned_text = clean(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e9018b",
   "metadata": {},
   "source": [
    "##### Now we will break the string into single words and count the frequencies.\n",
    "##### That is, tokenize, count and store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f0679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most used words:\n",
      "       iiser : 15\n",
      "      mohali : 14\n",
      "          of : 8\n",
      "     science : 6\n",
      "    sciences : 6\n",
      "   committee : 6\n",
      "    research : 5\n",
      "         day : 5\n",
      "    students : 5\n",
      "   institute : 4\n",
      "          at : 4\n",
      "     faculty : 4\n",
      "        news : 4\n",
      "   academics : 3\n",
      " celebration : 3\n",
      "          by : 3\n",
      "         hon : 3\n",
      "         ble : 3\n",
      "         the : 3\n",
      "        vice : 3\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_words(cleaned_text: str) -> Counter:\n",
    "    \"\"\"\n",
    "    Takes a cleaned text string (only lowercase letters and spaces),\n",
    "    returns a Counter mapping word -> frequency.\n",
    "    \"\"\"\n",
    "\n",
    "    words = cleaned_text.split() # splits the cleaned string over white spaces\n",
    "\n",
    "    word_counter = Counter(words) # gets frequency of words   \n",
    "\n",
    "    return word_counter\n",
    "\n",
    "Counted_words = count_words(cleaned_text)\n",
    "most_used = Counted_words.most_common(20)\n",
    "\n",
    "print(\"Top 10 most used words:\")\n",
    "for word,freq in most_used:\n",
    "    print(f\"{word:>12} : {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef300e",
   "metadata": {},
   "source": [
    "Now, we need to store data. It is database where we can query, filter and join across multiple sites later.\n",
    "\n",
    "CSV is static: you can only store and read rows.\n",
    "SQLite is dynamic: you can query — “show words used more than 50 times,” or “compare IISER Mohali vs Pune.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed40035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def store_sqlite(word_counts: Counter, db_path='words.db', table='word_frequency'):\n",
    "    # word_counts: Counter — our counted data from earlier (Counter is like a dict: {word: freq}).\n",
    "    # db_path='words.db' — the name of the database file.\n",
    "    # table='word_frequency' — the name of the SQL table to store data in.\n",
    "\n",
    "    # Connect to the database \n",
    "    conn = sqlite3.connect(db_path) # Opens (or creates) a database file. conn is the returned object here -> active connection to that database.\n",
    "    cur = conn.cursor() # Gives you a cursor, which is like a “pen” used to execute SQL commands.\n",
    "    #SQL databases work transactionally — you make changes through a cursor, then commit them all at once.\n",
    "\n",
    "    # Create table\n",
    "    cur.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table} (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            word TEXT UNIQUE,\n",
    "            frequency INTEGER\n",
    "        )\n",
    "    \"\"\")\n",
    "        # id INTEGER PRIMARY KEY AUTOINCREMENT → auto numbering for each row.\n",
    "        # word TEXT UNIQUE → ensures no duplicates (each word appears once).\n",
    "        # frequency INTEGER → stores how often the word appears.\n",
    "        # SQL needs data types. TEXT for words, INTEGER for counts.\n",
    "\n",
    "    # updating the table, putting values in it.\n",
    "    for i , freq in word_counts.items(): # loop over all wordandfreqency pairs\n",
    "        cur.execute(f\"\"\"\n",
    "            INSERT INTO {table} (word , frequency)\n",
    "            VALUES (? , ?)\n",
    "            ON CONFLICT(word) DO UPDATE SET frequency = excluded.frequency\n",
    "        \"\"\", (i,freq))\n",
    "        # executing againusing the cursor, \n",
    "        # INSERT INTO {table} (word , frequency) VALUES (? , ?) ---->>>> adds a new row\n",
    "        # ? -> replaced by (i, freq), \n",
    "        # ON CONFLICT(word) DO UPDATE --->>> if same word then update earlier thing.\n",
    "\n",
    "    ## save the changes.\n",
    "    conn.commit() # permanently writes all pending changes to disk.\n",
    "    conn.close() # ends the database session freeign the used resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now to read the stored data back, we proceed as.\n",
    "\n",
    "def read_sql(db_path='words.db', table='word_frequency', top=20):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"SELECT word , frequency FROM {table} ORDER BY frequency DESC LIMIT ?\", (top,))\n",
    "    rows = cur.fetchall()\n",
    "    conn.close\n",
    "    return rows  \n",
    "\n",
    "## It do as:\n",
    "# SELECT word, frequency\n",
    "# FROM word_frequency\n",
    "# ORDER BY frequency DESC\n",
    "# LIMIT top = 20;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5ff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       iiser  15\n",
      "      mohali  14\n",
      "          of  8\n",
      "     science  6\n",
      "    sciences  6\n",
      "   committee  6\n",
      "    research  5\n",
      "         day  5\n",
      "    students  5\n",
      "   institute  4\n",
      "          at  4\n",
      "     faculty  4\n",
      "        news  4\n",
      "   academics  3\n",
      " celebration  3\n",
      "          by  3\n",
      "         hon  3\n",
      "         ble  3\n",
      "         the  3\n",
      "        vice  3\n"
     ]
    }
   ],
   "source": [
    "store_sqlite(Counted_words)\n",
    "TOP_20 = read_sql()\n",
    "for w, f in TOP_20:\n",
    "    print(f\"{w:>12}  {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf82ac0f",
   "metadata": {},
   "source": [
    "#### Now we sqlite3 DB, we need to store multiple sites data into it, iteratively or seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa3b83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://www.iisermohali.ac.in/\n",
      "Unique words (Mohali): 212\n",
      "Top 10 (Mohali): [('iiser', 15), ('mohali', 14), ('of', 8), ('science', 6), ('sciences', 6), ('committee', 6), ('research', 5), ('day', 5), ('students', 5), ('institute', 4)]\n",
      "Stored Mohali counts in DB.\n",
      "\n",
      "Scraping: https://www.iiserpune.ac.in/\n",
      "Stored Pune counts in DB.\n",
      "\n",
      "Top words - Mohali:\n",
      "          iiser  15\n",
      "         mohali  14\n",
      "             of  8\n",
      "      committee  6\n",
      "        science  6\n",
      "       sciences  6\n",
      "            day  5\n",
      "       research  5\n",
      "       students  5\n",
      "             at  4\n",
      "        faculty  4\n",
      "      institute  4\n",
      "           news  4\n",
      "      academics  3\n",
      "            ble  3\n",
      "             by  3\n",
      "       calendar  3\n",
      "    celebration  3\n",
      "     committees  3\n",
      "         events  3\n",
      "\n",
      "Top words - Pune:\n",
      "            and  36\n",
      "            the  22\n",
      "             in  20\n",
      "             of  17\n",
      "          iiser  15\n",
      "           pune  15\n",
      "       research  15\n",
      "         events  11\n",
      "             on  11\n",
      "         campus  10\n",
      "        faculty  10\n",
      "             at  9\n",
      "            for  9\n",
      "        science  9\n",
      "             by  8\n",
      "        fellows  8\n",
      "        members  8\n",
      "           more  8\n",
      "           news  8\n",
      "         posted  8\n",
      "\n",
      "Top common words (by sum of frequencies):\n",
      "          iiser  Mohali:   15  Pune:   15\n",
      "             of  Mohali:    8  Pune:   17\n",
      "            the  Mohali:    3  Pune:   22\n",
      "             in  Mohali:    2  Pune:   20\n",
      "       research  Mohali:    5  Pune:   15\n",
      "        science  Mohali:    6  Pune:    9\n",
      "         events  Mohali:    3  Pune:   11\n",
      "        faculty  Mohali:    4  Pune:   10\n",
      "             at  Mohali:    4  Pune:    9\n",
      "         campus  Mohali:    2  Pune:   10\n",
      "           news  Mohali:    4  Pune:    8\n",
      "             by  Mohali:    3  Pune:    8\n",
      "            for  Mohali:    2  Pune:    9\n",
      "       sciences  Mohali:    6  Pune:    4\n",
      "             dr  Mohali:    2  Pune:    7\n",
      "        members  Mohali:    1  Pune:    8\n",
      "             to  Mohali:    2  Pune:    7\n",
      "         alumni  Mohali:    1  Pune:    7\n",
      "            day  Mohali:    5  Pune:    3\n",
      "             as  Mohali:    1  Pune:    6\n",
      "      committee  Mohali:    6  Pune:    1\n",
      "        elected  Mohali:    1  Pune:    6\n",
      "     facilities  Mohali:    3  Pune:    4\n",
      "          india  Mohali:    2  Pune:    5\n",
      "          media  Mohali:    1  Pune:    6\n",
      "\n",
      "Top words unique to Mohali (not in Pune):\n",
      "         mohali  14\n",
      "    celebration  3\n",
      "     committees  3\n",
      "      president  3\n",
      "           vice  3\n",
      "   achievements  2\n",
      "        awarded  2\n",
      "        careers  2\n",
      "     complaints  2\n",
      "       computer  2\n",
      "       festival  2\n",
      "        holiday  2\n",
      "            icc  2\n",
      "     institutes  2\n",
      "          rules  2\n",
      "         school  2\n",
      "         system  2\n",
      "             th  2\n",
      "        website  2\n",
      "      academies  1\n",
      "         across  1\n",
      " administration  1\n",
      " administrative  1\n",
      "      admission  1\n",
      " advertisements  1\n",
      "       advisory  1\n",
      "       agencies  1\n",
      "           anil  1\n",
      "          anjan  1\n",
      "         annual  1\n"
     ]
    }
   ],
   "source": [
    "# Complete end-to-end: scrape -> clean -> count -> store -> compare\n",
    "# Requirements: requests, beautifulsoup4\n",
    "# Run: pip install requests beautifulsoup4  (if not installed)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import sqlite3\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "# -------------------------\n",
    "# Scrape + clean functions\n",
    "# -------------------------\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert to lowercase, remove non-letters except spaces,\n",
    "    remove stray single letters except 'a' and 'i', normalize whitespace.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)               # keep only a-z and whitespace\n",
    "    text = re.sub(r'\\b(?![ai]\\b)[a-z]\\b', ' ', text)    # remove single letters except 'a' and 'i'\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()            # collapse spaces\n",
    "    return text\n",
    "\n",
    "def scrape_text_from_url(url: str, valid_tags=None, timeout=12) -> str:\n",
    "    \"\"\"\n",
    "    Fetch URL, parse HTML, extract text from valid_tags, then clean it.\n",
    "    Returns cleaned text string.\n",
    "    \"\"\"\n",
    "    if valid_tags is None:\n",
    "        valid_tags = ['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'li']\n",
    "\n",
    "    response = requests.get(url, timeout=timeout)\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(f\"Failed to fetch {url} (status {response.status_code})\")\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    pieces = [el.get_text(separator=' ', strip=True) for el in soup.find_all(valid_tags)]\n",
    "    raw_text = \" \".join(pieces)\n",
    "    return clean_text(raw_text)\n",
    "\n",
    "# -------------------------\n",
    "# Counting function\n",
    "# -------------------------\n",
    "def count_words(cleaned_text: str) -> Counter:\n",
    "    words = cleaned_text.split()\n",
    "    return Counter(words)\n",
    "\n",
    "# -------------------------\n",
    "# SQLite storage functions (single table for all sites)\n",
    "# -------------------------\n",
    "def store_site_word_counts(\n",
    "    word_counts: Counter,\n",
    "    site: str,\n",
    "    db_path: str = \"words.db\",\n",
    "    table: str = \"word_frequency\",\n",
    "    accumulate: bool = True\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Store counts for a given site into SQLite.\n",
    "    - accumulate=True : add new counts to existing (useful for incremental scraping)\n",
    "    - accumulate=False: replace stored counts for that site (snapshot)\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Create table holding rows for many sites (site, word, frequency)\n",
    "    cur.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table} (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            site TEXT NOT NULL,\n",
    "            word TEXT NOT NULL,\n",
    "            frequency INTEGER NOT NULL,\n",
    "            UNIQUE(site, word)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    if accumulate:\n",
    "        # add new counts to existing frequency\n",
    "        upsert_sql = f\"\"\"\n",
    "            INSERT INTO {table} (site, word, frequency)\n",
    "            VALUES (?, ?, ?)\n",
    "            ON CONFLICT(site, word) DO UPDATE\n",
    "              SET frequency = {table}.frequency + excluded.frequency\n",
    "        \"\"\"\n",
    "    else:\n",
    "        # replace stored frequency with the new one\n",
    "        upsert_sql = f\"\"\"\n",
    "            INSERT INTO {table} (site, word, frequency)\n",
    "            VALUES (?, ?, ?)\n",
    "            ON CONFLICT(site, word) DO UPDATE\n",
    "              SET frequency = excluded.frequency\n",
    "        \"\"\"\n",
    "\n",
    "    for w, freq in word_counts.items():\n",
    "        cur.execute(upsert_sql, (site, w, int(freq)))\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def read_top_by_site(\n",
    "    site: str,\n",
    "    db_path: str = \"words.db\",\n",
    "    table: str = \"word_frequency\",\n",
    "    top: int = 20\n",
    ") -> List[Tuple[str, int]]:\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"SELECT word, frequency FROM {table} WHERE site = ? ORDER BY frequency DESC LIMIT ?\", (site, top))\n",
    "    rows = cur.fetchall()\n",
    "    conn.close()\n",
    "    return rows\n",
    "\n",
    "def compare_sites_common(\n",
    "    site1: str,\n",
    "    site2: str,\n",
    "    db_path: str = \"words.db\",\n",
    "    table: str = \"word_frequency\",\n",
    "    top: int = 30,\n",
    "    sort_by: str = \"sum\"  # \"sum\" | \"min\" | \"diff\"\n",
    ") -> List[Tuple[str, int, int]]:\n",
    "    \"\"\"\n",
    "    Return common words between site1 and site2 as (word, freq_site1, freq_site2).\n",
    "    sort_by:\n",
    "      - 'sum' : sort by freq1+freq2 descending (default)\n",
    "      - 'min' : sort by min(freq1,freq2) descending -> words both strongly used\n",
    "      - 'diff': sort by absolute difference descending -> most differently-used words\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cur = conn.cursor()\n",
    "    sql = f\"\"\"\n",
    "        SELECT a.word, a.frequency AS f1, b.frequency AS f2\n",
    "        FROM {table} a\n",
    "        JOIN {table} b ON a.word = b.word\n",
    "        WHERE a.site = ? AND b.site = ?\n",
    "    \"\"\"\n",
    "    cur.execute(sql, (site1, site2))\n",
    "    rows = cur.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    if sort_by == \"sum\":\n",
    "        rows_sorted = sorted(rows, key=lambda r: (r[1] + r[2]), reverse=True)\n",
    "    elif sort_by == \"min\":\n",
    "        rows_sorted = sorted(rows, key=lambda r: min(r[1], r[2]), reverse=True)\n",
    "    elif sort_by == \"diff\":\n",
    "        rows_sorted = sorted(rows, key=lambda r: abs(r[1] - r[2]), reverse=True)\n",
    "    else:\n",
    "        rows_sorted = rows\n",
    "\n",
    "    return rows_sorted[:top]\n",
    "\n",
    "def unique_to_site(\n",
    "    site1: str,\n",
    "    site2: str,\n",
    "    db_path: str = \"words.db\",\n",
    "    table: str = \"word_frequency\",\n",
    "    top: int = 50\n",
    ") -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Words present in site1 but NOT in site2 (ordered by frequency in site1).\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cur = conn.cursor()\n",
    "    sql = f\"\"\"\n",
    "        SELECT a.word, a.frequency\n",
    "        FROM {table} a\n",
    "        LEFT JOIN {table} b ON a.word = b.word AND b.site = ?\n",
    "        WHERE a.site = ? AND b.word IS NULL\n",
    "        ORDER BY a.frequency DESC\n",
    "        LIMIT ?\n",
    "    \"\"\"\n",
    "    cur.execute(sql, (site2, site1, top))\n",
    "    rows = cur.fetchall()\n",
    "    conn.close()\n",
    "    return rows\n",
    "\n",
    "# -------------------------\n",
    "# Example end-to-end usage\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: single site (IISER Mohali)\n",
    "    mohali_url = \"https://www.iisermohali.ac.in/\"\n",
    "    print(\"Scraping:\", mohali_url)\n",
    "    cleaned_mohali_text = scrape_text_from_url(mohali_url)\n",
    "    word_counts_mohali = count_words(cleaned_mohali_text)\n",
    "    print(\"Unique words (Mohali):\", len(word_counts_mohali))\n",
    "    print(\"Top 10 (Mohali):\", word_counts_mohali.most_common(10))\n",
    "\n",
    "    # Store in DB (accumulate=True => add counts if site already present)\n",
    "    store_site_word_counts(word_counts_mohali, site=mohali_url, accumulate=True)\n",
    "    print(\"Stored Mohali counts in DB.\")\n",
    "\n",
    "    # Example 2: another site (IISER Pune) - optional\n",
    "    pune_url = \"https://www.iiserpune.ac.in/\"\n",
    "    print(\"\\nScraping:\", pune_url)\n",
    "    cleaned_pune_text = scrape_text_from_url(pune_url)\n",
    "    word_counts_pune = count_words(cleaned_pune_text)\n",
    "    store_site_word_counts(word_counts_pune, site=pune_url, accumulate=True)\n",
    "    print(\"Stored Pune counts in DB.\")\n",
    "\n",
    "    # Read and display top words for each site\n",
    "    print(\"\\nTop words - Mohali:\")\n",
    "    for w, f in read_top_by_site(mohali_url, top=20):\n",
    "        print(f\"{w:>15}  {f}\")\n",
    "    print(\"\\nTop words - Pune:\")\n",
    "    for w, f in read_top_by_site(pune_url, top=20):\n",
    "        print(f\"{w:>15}  {f}\")\n",
    "\n",
    "    # Compare common words\n",
    "    print(\"\\nTop common words (by sum of frequencies):\")\n",
    "    for word, f1, f2 in compare_sites_common(mohali_url, pune_url, top=25, sort_by=\"sum\"):\n",
    "        print(f\"{word:>15}  Mohali:{f1:5d}  Pune:{f2:5d}\")\n",
    "\n",
    "    # Words unique to Mohali (not in Pune)\n",
    "    print(\"\\nTop words unique to Mohali (not in Pune):\")\n",
    "    for w, f in unique_to_site(mohali_url, pune_url, top=30):\n",
    "        print(f\"{w:>15}  {f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dsenv)",
   "language": "python",
   "name": "dsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
